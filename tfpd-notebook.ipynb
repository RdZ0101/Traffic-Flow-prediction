{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be66d9d-8dde-4af9-ac25-77248ce9d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the data\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "def process_data(train, test, lags):\n",
    "    \"\"\"Process data\n",
    "    Reshape and split train\\test data.\n",
    "\n",
    "    # Arguments\n",
    "        train: String, name of .csv train file.\n",
    "        test: String, name of .csv test file.\n",
    "        lags: integer, time lag.\n",
    "    # Returns\n",
    "        X_train: ndarray.\n",
    "        y_train: ndarray.\n",
    "        X_test: ndarray.\n",
    "        y_test: ndarray.\n",
    "        scaler: StandardScaler.\n",
    "    \"\"\"\n",
    "    attr = 'VFlow'\n",
    "    df1 = pd.read_csv(train, encoding='utf-8').fillna(0)\n",
    "    df2 = pd.read_csv(test, encoding='utf-8').fillna(0)\n",
    "\n",
    "    # scaler = StandardScaler().fit(df1[attr].values)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(df1[attr].values.reshape(-1, 1))\n",
    "    flow1 = scaler.transform(df1[attr].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "    flow2 = scaler.transform(df2[attr].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "\n",
    "    train, test = [], []\n",
    "    for i in range(lags, len(flow1)):\n",
    "        train.append(flow1[i - lags: i + 1])\n",
    "    for i in range(lags, len(flow2)):\n",
    "        test.append(flow2[i - lags: i + 1])\n",
    "\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    np.random.shuffle(train)\n",
    "\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    X_test = test[:, :-1]\n",
    "    y_test = test[:, -1]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c64ce5-c349-4300-afc2-dc14ea212d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, name, config):\n",
    "    \"\"\"train\n",
    "    train a single model.\n",
    "\n",
    "    # Arguments\n",
    "        model: Model, NN model to train.\n",
    "        X_train: ndarray(number, lags), Input data for train.\n",
    "        y_train: ndarray(number, ), result data for train.\n",
    "        name: String, name of model.\n",
    "        config: Dict, parameter for train.\n",
    "    \"\"\"\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mape'])\n",
    "    # early = EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')\n",
    "    hist = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=config[\"batch\"],\n",
    "        epochs=config[\"epochs\"],\n",
    "        validation_split=0.05)\n",
    "\n",
    "    model.save('model/' + name + '.h5')\n",
    "    df = pd.DataFrame.from_dict(hist.history)\n",
    "    df.to_csv('model/' + name + ' loss.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c26c2bb5-6380-4e43-b414-b36706c1cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train(model_name):\n",
    "    lag = 12\n",
    "    config = {\"batch\": 256, \"epochs\": 500}\n",
    "    file1 = 'data/train.csv'\n",
    "    file2 = 'data/test.csv'\n",
    "    X_train, y_train, _, _, _ = process_data(file1, file2, lag)\n",
    "\n",
    "    if model_name == 'lstm':\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "        m = get_lstm([12, 64, 64, 1])\n",
    "        train_model(m, X_train, y_train, model_name, config)\n",
    "    if model_name == 'gru':\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "        m = get_gru([12, 64, 64, 1])\n",
    "        train_model(m, X_train, y_train, model_name, config)\n",
    "    if model_name == 'saes':\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]))\n",
    "        m = get_saes([12, 400, 400, 400, 1])\n",
    "        train_seas(m, X_train, y_train, model_name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8de77804-582c-402c-8dfc-02a53b284da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defination of NN model\n",
    "\"\"\"\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "def get_lstm(units):\n",
    "    \"\"\"LSTM(Long Short-Term Memory)\n",
    "    Build LSTM Model.\n",
    "\n",
    "    # Arguments\n",
    "        units: List(int), number of input, output and hidden units.\n",
    "    # Returns\n",
    "        model: Model, nn model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units[1], input_shape=(units[0], 1), return_sequences=True))\n",
    "    model.add(LSTM(units[2]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units[3], activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_gru(units):\n",
    "    \"\"\"GRU(Gated Recurrent Unit)\n",
    "    Build GRU Model.\n",
    "\n",
    "    # Arguments\n",
    "        units: List(int), number of input, output and hidden units.\n",
    "    # Returns\n",
    "        model: Model, nn model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units[1], input_shape=(units[0], 1), return_sequences=True))\n",
    "    model.add(GRU(units[2]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units[3], activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def _get_sae(inputs, hidden, output):\n",
    "    \"\"\"SAE(Auto-Encoders)\n",
    "    Build SAE Model.\n",
    "\n",
    "    # Arguments\n",
    "        inputs: Integer, number of input units.\n",
    "        hidden: Integer, number of hidden units.\n",
    "        output: Integer, number of output units.\n",
    "    # Returns\n",
    "        model: Model, nn model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden, input_dim=inputs, name='hidden'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(output, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_saes(layers):\n",
    "    \"\"\"SAEs(Stacked Auto-Encoders)\n",
    "    Build SAEs Model.\n",
    "\n",
    "    # Arguments\n",
    "        layers: List(int), number of input, output and hidden units.\n",
    "    # Returns\n",
    "        models: List(Model), List of SAE and SAEs.\n",
    "    \"\"\"\n",
    "    sae1 = _get_sae(layers[0], layers[1], layers[-1])\n",
    "    sae2 = _get_sae(layers[1], layers[2], layers[-1])\n",
    "    sae3 = _get_sae(layers[2], layers[3], layers[-1])\n",
    "\n",
    "    saes = Sequential()\n",
    "    saes.add(Dense(layers[1], input_dim=layers[0], name='hidden1'))\n",
    "    saes.add(Activation('sigmoid'))\n",
    "    saes.add(Dense(layers[2], name='hidden2'))\n",
    "    saes.add(Activation('sigmoid'))\n",
    "    saes.add(Dense(layers[3], name='hidden3'))\n",
    "    saes.add(Activation('sigmoid'))\n",
    "    saes.add(Dropout(0.2))\n",
    "    saes.add(Dense(layers[4], activation='sigmoid'))\n",
    "\n",
    "    models = [sae1, sae2, sae3, saes]\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47448d3a-883f-4dbf-963e-6e8b843c6895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seas(models, X_train, y_train, name, config):\n",
    "    \"\"\"train\n",
    "    train the SAEs model.\n",
    "\n",
    "    # Arguments\n",
    "        models: List, list of SAE model.\n",
    "        X_train: ndarray(number, lags), Input data for train.\n",
    "        y_train: ndarray(number, ), result data for train.\n",
    "        name: String, name of model.\n",
    "        config: Dict, parameter for train.\n",
    "    \"\"\"\n",
    "\n",
    "    temp = X_train\n",
    "    # early = EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')\n",
    "\n",
    "    for i in range(len(models) - 1):\n",
    "        if i > 0:\n",
    "            p = models[i - 1]\n",
    "            hidden_layer_model = Model(input=p.input,\n",
    "                                       output=p.get_layer('hidden').output)\n",
    "            temp = hidden_layer_model.predict(temp)\n",
    "\n",
    "        m = models[i]\n",
    "        m.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mape'])\n",
    "\n",
    "        m.fit(temp, y_train, batch_size=config[\"batch\"],\n",
    "              epochs=config[\"epochs\"],\n",
    "              validation_split=0.05)\n",
    "\n",
    "        models[i] = m\n",
    "\n",
    "    saes = models[-1]\n",
    "    for i in range(len(models) - 1):\n",
    "        weights = models[i].get_layer('hidden').get_weights()\n",
    "        saes.get_layer('hidden%d' % (i + 1)).set_weights(weights)\n",
    "\n",
    "    train_model(saes, X_train, y_train, name, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dcd032-234a-4c37-9c62-199d468707a4",
   "metadata": {},
   "source": [
    "## warning: this stuff will take ages to run and needs GPU time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ff6beca-888d-464e-b03c-8ab1495a2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a4262-c4af-446a-a12a-7340bdf5bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train('saes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafdd7f1-d5e6-42f3-8b2a-db698765f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train('gru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d84c87-fa0d-48dc-badd-fe5d72500cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train('lstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5848666c-4703-4c41-b2ce-adbdc15fba6b",
   "metadata": {},
   "source": [
    "## end of warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbbcf119-a8e0-4982-8fe3-69fcffaf9164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.src.legacy.saving import legacy_h5_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "417c6ad1-66f8-4c35-91f2-958234b87700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred):\n",
    "    \"\"\"Mean Absolute Percentage Error\n",
    "    Calculate the mape.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: List/ndarray, ture data.\n",
    "        y_pred: List/ndarray, predicted data.\n",
    "    # Returns\n",
    "        mape: Double, result data for train.\n",
    "    \"\"\"\n",
    "\n",
    "    y = [x for x in y_true if x > 0]\n",
    "    y_pred = [y_pred[i] for i in range(len(y_true)) if y_true[i] > 0]\n",
    "\n",
    "    num = len(y_pred)\n",
    "    sums = 0\n",
    "\n",
    "    for i in range(num):\n",
    "        tmp = abs(y[i] - y_pred[i]) / y[i]\n",
    "        sums += tmp\n",
    "\n",
    "    mape = sums * (100 / num)\n",
    "\n",
    "    return mape\n",
    "\n",
    "\n",
    "def eva_regress(y_true, y_pred):\n",
    "    \"\"\"Evaluation\n",
    "    evaluate the predicted resul.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: List/ndarray, ture data.\n",
    "        y_pred: List/ndarray, predicted data.\n",
    "    \"\"\"\n",
    "\n",
    "    mape = MAPE(y_true, y_pred)\n",
    "    vs = metrics.explained_variance_score(y_true, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "    print('explained_variance_score:%f' % vs)\n",
    "    print('mape:%f%%' % mape)\n",
    "    print('mae:%f' % mae)\n",
    "    print('mse:%f' % mse)\n",
    "    print('rmse:%f' % math.sqrt(mse))\n",
    "    print('r2:%f' % r2)\n",
    "\n",
    "def plot_results(y_true, y_preds, names):\n",
    "    \"\"\"Plot\n",
    "    Plot the true data and predicted data.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: List/ndarray, ture data.\n",
    "        y_pred: List/ndarray, predicted data.\n",
    "        names: List, Method names.\n",
    "    \"\"\"\n",
    "    d = '2016-3-4 00:00'\n",
    "    x = pd.date_range(d, periods=96, freq='15min')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.plot(x, y_true, label='True Data')\n",
    "    for name, y_pred in zip(names, y_preds):\n",
    "        ax.plot(x, y_pred, label=name)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time of Day')\n",
    "    plt.ylabel('Flow')\n",
    "\n",
    "    date_format = mpl.dates.DateFormatter(\"%H:%M\")\n",
    "    ax.xaxis.set_major_formatter(date_format)\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "\n",
    "def main():\n",
    "    #lstm = load_model('model/lstm.h5')\n",
    "    gru = legacy_h5_format.load_model_from_hdf5(\"model/gru.h5\", custom_objects={'mse': 'mse'})\n",
    "    #saes = legacy_h5_format.load_model_from_hdf5(\"model/saes.h5\", custom_objects={'mse': 'mse'})\n",
    "    lstm = legacy_h5_format.load_model_from_hdf5(\"model/lstm.h5\", custom_objects={'mse': 'mse'})\n",
    "    models = [lstm, gru]#, saes]\n",
    "    names = ['LSTM', 'GRU']#, 'SAEs']\n",
    "\n",
    "    lag = 12\n",
    "    file1 = 'data/train.csv'\n",
    "    file2 = 'data/test.csv'\n",
    "    _, _, X_test, y_test, scaler = process_data(file1, file2, lag)\n",
    "    y_test = scaler.inverse_transform(y_test.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "\n",
    "    y_preds = []\n",
    "    for name, model in zip(names, models):\n",
    "        if name == 'SAEs':\n",
    "            X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1]))\n",
    "        else:\n",
    "            X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "        file = 'images/' + name + '.png'\n",
    "        plot_model(model, to_file=file, show_shapes=True)\n",
    "        predicted = model.predict(X_test)\n",
    "        predicted = scaler.inverse_transform(predicted.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "        y_preds.append(predicted[:96])\n",
    "        print(name)\n",
    "        eva_regress(y_test, predicted)\n",
    "\n",
    "    plot_results(y_test[: 96], y_preds, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d8237a-4b68-443a-8616-478e0c318a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc84eb-3a19-40bc-864d-273d24861cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
