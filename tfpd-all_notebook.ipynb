{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be66d9d-8dde-4af9-ac25-77248ce9d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the data\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "def process_data(train, test, lags):\n",
    "    \"\"\"Process data\n",
    "    Reshape and split train\\test data.\n",
    "\n",
    "    # Arguments\n",
    "        train: String, name of .csv train file.\n",
    "        test: String, name of .csv test file.\n",
    "        lags: integer, time lag.\n",
    "    # Returns\n",
    "        X_train: ndarray.\n",
    "        y_train: ndarray.\n",
    "        X_test: ndarray.\n",
    "        y_test: ndarray.\n",
    "        scaler: StandardScaler.\n",
    "    \"\"\"\n",
    "    attr = 'VFlow'\n",
    "    df1 = pd.read_csv(train, encoding='utf-8').fillna(0)\n",
    "    df2 = pd.read_csv(test, encoding='utf-8').fillna(0)\n",
    "\n",
    "    # scaler = StandardScaler().fit(df1[attr].values)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(df1[attr].values.reshape(-1, 1))\n",
    "    flow1 = scaler.transform(df1[attr].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "    flow2 = scaler.transform(df2[attr].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "\n",
    "    train, test = [], []\n",
    "    for i in range(lags, len(flow1)):\n",
    "        train.append(flow1[i - lags: i + 1])\n",
    "    for i in range(lags, len(flow2)):\n",
    "        test.append(flow2[i - lags: i + 1])\n",
    "\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    np.random.shuffle(train)\n",
    "\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    X_test = test[:, :-1]\n",
    "    y_test = test[:, -1]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c64ce5-c349-4300-afc2-dc14ea212d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, name, scats_number, config):\n",
    "    \"\"\"train\n",
    "    train a single model.\n",
    "\n",
    "    # Arguments\n",
    "        model: Model, NN model to train.\n",
    "        X_train: ndarray(number, lags), Input data for train.\n",
    "        y_train: ndarray(number, ), result data for train.\n",
    "        name: String, name of model.\n",
    "        config: Dict, parameter for train.\n",
    "    \"\"\"\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mape'])\n",
    "    # early = EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')\n",
    "    hist = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=config[\"batch\"],\n",
    "        epochs=config[\"epochs\"],\n",
    "        validation_split=0.05,\n",
    "        verbose=0)\n",
    "\n",
    "    #Create folder structure: model/<model_name>/<scats_number>\n",
    "    model_folder = f'model/{name}/{scats_number}'\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "    #Save the model and loss history\n",
    "    model.save(f'{model_folder}/{name}_{scats_number}.h5')\n",
    "    df = pd.DataFrame.from_dict(hist.history)\n",
    "    df.to_csv(f'{model_folder}/{name}_{scats_number}_loss.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c26c2bb5-6380-4e43-b414-b36706c1cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def do_train(model_name):\n",
    "    lag = 12\n",
    "    config = {\"batch\": 256, \"epochs\": 500}\n",
    "\n",
    "    train_folder = 'intersection/train/'\n",
    "    test_folder = 'intersection/test/'\n",
    "\n",
    "    for filename in os.listdir(train_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            scats_number = filename.split('_')[1].split('.')[0]\n",
    "            train_file = os.path.join(train_folder, filename)\n",
    "            test_file = os.path.join(test_folder, f\"test_{scats_number}.csv\")\n",
    "\n",
    "            print(f\"Processing SCATS Number: {scats_number}\")\n",
    "\n",
    "            X_train, y_train, X_test, y_test, scaler = process_data(train_file, test_file, lag)\n",
    "\n",
    "            model_file_name = model_name\n",
    "\n",
    "            if model_name == 'lstm':\n",
    "                X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "                m = get_lstm([12, 64, 64, 1])\n",
    "                train_model(m, X_train, y_train, model_file_name, scats_number, config)\n",
    "\n",
    "            elif model_name == 'gru':\n",
    "                X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "                m = get_gru([12, 64, 64, 1])\n",
    "                train_model(m, X_train, y_train, model_file_name, scats_number, config)\n",
    "\n",
    "            elif model_name == 'saes':\n",
    "                X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]))\n",
    "                m = get_saes([12, 400, 400, 400, 1])\n",
    "                train_seas(m, X_train, y_train, model_file_name, scats_number, config)\n",
    "            \n",
    "            elif model_name == 'nt_saes':\n",
    "                X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]))\n",
    "                m = get_nt_saes([12, 400, 400, 400, 1])\n",
    "                train_nt_saes(m, X_train, y_train, model_file_name, scats_number, config)\n",
    "\n",
    "            print(f\"Saved model for SCATS Number: {scats_number}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de77804-582c-402c-8dfc-02a53b284da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 22:04:23.321113: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-16 22:04:23.389584: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-16 22:04:23.408128: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-16 22:04:23.525316: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-16 22:04:24.442760: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Defination of NN model\n",
    "\"\"\"\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Input, LSTM, GRU, Dense \n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "def get_lstm(units):\n",
    "    \"\"\"LSTM(Long Short-Term Memory)\n",
    "    Build LSTM Model.\n",
    "\n",
    "    # Arguments\n",
    "        units: List(int), number of input, output and hidden units.\n",
    "    # Returns\n",
    "        model: Model, nn model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(units[0], 1)))\n",
    "    model.add(LSTM(units[1], return_sequences=True))\n",
    "    model.add(LSTM(units[2]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units[3], activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_gru(units):\n",
    "    \"\"\"GRU(Gated Recurrent Unit)\n",
    "    Build GRU Model.\n",
    "\n",
    "    # Arguments\n",
    "        units: List(int), number of input, output and hidden units.\n",
    "    # Returns\n",
    "        model: Model, nn model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units[1], input_shape=(units[0], 1), return_sequences=True))\n",
    "    model.add(GRU(units[2]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units[3], activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def _get_nt_sae(inputs, hidden, output):\n",
    "    \"\"\"SAE(Auto-Encoders)\n",
    "    Build SAE Model.\n",
    "\n",
    "    # Arguments\n",
    "        inputs: Integer, number of input units.\n",
    "        hidden: Integer, number of hidden units.\n",
    "        output: Integer, number of output units.\n",
    "    # Returns\n",
    "        model: Model, nn model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden, input_dim=inputs, name='hidden'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(output, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_nt_saes(layers):\n",
    "    \"\"\"SAEs(Stacked Auto-Encoders)\n",
    "    Build SAEs Model.\n",
    "\n",
    "    # Arguments\n",
    "        layers: List(int), number of input, output and hidden units.\n",
    "    # Returns\n",
    "        models: List(Model), List of SAE and SAEs.\n",
    "    \"\"\"\n",
    "    sae1 = _get_nt_sae(layers[0], layers[1], layers[-1])\n",
    "    sae2 = _get_nt_sae(layers[1], layers[2], layers[-1])\n",
    "    sae3 = _get_nt_sae(layers[2], layers[3], layers[-1])\n",
    "\n",
    "    saes = Sequential()\n",
    "    saes.add(Dense(layers[1], input_dim=layers[0], name='hidden1'))\n",
    "    saes.add(Activation('sigmoid'))\n",
    "    saes.add(Dense(layers[2], name='hidden2'))\n",
    "    saes.add(Activation('sigmoid'))\n",
    "    saes.add(Dense(layers[3], name='hidden3'))\n",
    "    saes.add(Activation('sigmoid'))\n",
    "    saes.add(Dropout(0.2))\n",
    "    saes.add(Dense(layers[4], activation='sigmoid'))\n",
    "\n",
    "    models = [sae1, sae2, sae3, saes]\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47448d3a-883f-4dbf-963e-6e8b843c6895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nt_saes(models, X_train, y_train, name, scats_number, config):\n",
    "    \"\"\"train\n",
    "    train the SAEs model.\n",
    "\n",
    "    # Arguments\n",
    "        models: List, list of SAE model.\n",
    "        X_train: ndarray(number, lags), Input data for train.\n",
    "        y_train: ndarray(number, ), result data for train.\n",
    "        name: String, name of model.\n",
    "        config: Dict, parameter for train.\n",
    "    \"\"\"\n",
    "\n",
    "    temp = X_train\n",
    "    # early = EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')\n",
    "\n",
    "    for i in range(len(models) - 1):\n",
    "        if i > 0:\n",
    "            p = models[i - 1]\n",
    "            hidden_layer_model = Model(inputs=p.inputs,\n",
    "                                       outputs=p.get_layer('hidden').output)\n",
    "            temp = hidden_layer_model.predict(temp)\n",
    "\n",
    "        m = models[i]\n",
    "        m.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mape'])\n",
    "\n",
    "        m.fit(temp, y_train, batch_size=config[\"batch\"],\n",
    "              epochs=config[\"epochs\"],\n",
    "              validation_split=0.05)\n",
    "\n",
    "        models[i] = m\n",
    "\n",
    "    saes = models[-1]\n",
    "    for i in range(len(models) - 1):\n",
    "        weights = models[i].get_layer('hidden').get_weights()\n",
    "        saes.get_layer('hidden%d' % (i + 1)).set_weights(weights)\n",
    "\n",
    "    train_model(saes, X_train, y_train, name, scats_number, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dcd032-234a-4c37-9c62-199d468707a4",
   "metadata": {},
   "source": [
    "## warning: this stuff will take ages to run and needs GPU time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff6beca-888d-464e-b03c-8ab1495a2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9224eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train('sae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c38ce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train('nt_saes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78102b2c",
   "metadata": {},
   "source": [
    "START NEXT TRAIN FROM HERE!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafdd7f1-d5e6-42f3-8b2a-db698765f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train('gru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d84c87-fa0d-48dc-badd-fe5d72500cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train('lstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5848666c-4703-4c41-b2ce-adbdc15fba6b",
   "metadata": {},
   "source": [
    "## end of warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbbcf119-a8e0-4982-8fe3-69fcffaf9164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.src.legacy.saving import legacy_h5_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8701e764-c08b-4de5-b1fa-b344f18af267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred):\n",
    "    \"\"\"Mean Absolute Percentage Error\n",
    "    Calculate the mape.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: List/ndarray, ture data.\n",
    "        y_pred: List/ndarray, predicted data.\n",
    "    # Returns\n",
    "        mape: Double, result data for train.\n",
    "    \"\"\"\n",
    "\n",
    "    y = [x for x in y_true if x > 0]\n",
    "    y_pred = [y_pred[i] for i in range(len(y_true)) if y_true[i] > 0]\n",
    "\n",
    "    num = len(y_pred)\n",
    "    sums = 0\n",
    "\n",
    "    for i in range(num):\n",
    "        tmp = abs(y[i] - y_pred[i]) / y[i]\n",
    "        sums += tmp\n",
    "\n",
    "    mape = sums * (100 / num)\n",
    "\n",
    "    return mape\n",
    "\n",
    "\n",
    "def eva_regress(y_true, y_pred, silent=False):\n",
    "    \"\"\"Evaluation\n",
    "    evaluate the predicted resul.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: List/ndarray, ture data.\n",
    "        y_pred: List/ndarray, predicted data.\n",
    "    \"\"\"\n",
    "\n",
    "    mape = MAPE(y_true, y_pred)\n",
    "    vs = metrics.explained_variance_score(y_true, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "    \n",
    "    if not silent:\n",
    "        print('explained_variance_score:%f' % vs)\n",
    "        print('mape:%f%%' % mape)\n",
    "        print('mae:%f' % mae)\n",
    "        print('mse:%f' % mse)\n",
    "        print('rmse:%f' % math.sqrt(mse))\n",
    "        print('r2:%f' % r2)\n",
    "        \n",
    "    return mape, vs, mae, mse, r2\n",
    "\n",
    "def plot_results(y_true, y_preds, names):\n",
    "    \"\"\"Plot\n",
    "    Plot the true data and predicted data.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: List/ndarray, ture data.\n",
    "        y_pred: List/ndarray, predicted data.\n",
    "        names: List, Method names.\n",
    "    \"\"\"\n",
    "    d = '2016-3-4 00:00'\n",
    "    x = pd.date_range(d, periods=96, freq='15min')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.plot(x, y_true, label='True Data')\n",
    "    for name, y_pred in zip(names, y_preds):\n",
    "        ax.plot(x, y_pred, label=name)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time of Day')\n",
    "    plt.ylabel('Flow')\n",
    "\n",
    "    date_format = mpl.dates.DateFormatter(\"%H:%M\")\n",
    "    ax.xaxis.set_major_formatter(date_format)\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "\n",
    "def main():\n",
    "    lag = 12\n",
    "    train_folder = 'intersection/train/'\n",
    "    test_folder = 'intersection/test/'\n",
    "\n",
    "    models = ['lstm', 'gru', 'sae', 'nt_saes']\n",
    "    names = ['LSTM', 'GRU', 'SAE', 'NT_SAEs']\n",
    "\n",
    "    stats_row_list = []\n",
    "    \n",
    "    for filename in os.listdir(train_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            scats_number = filename.split('_')[1].split('.')[0]\n",
    "            train_file = os.path.join(train_folder, filename)\n",
    "            test_file = os.path.join(test_folder, f\"test_{scats_number}.csv\")\n",
    "\n",
    "            print(f\"Evaluating for SCATS Number: {scats_number}\")\n",
    "            _, _, X_test, y_test, scaler = process_data(train_file, test_file, lag)\n",
    "            y_test = scaler.inverse_transform(y_test.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "\n",
    "            y_preds = []\n",
    "\n",
    "            models_to_remove = []\n",
    "            for model_variant in models:\n",
    "                \n",
    "                try:\n",
    "                    model = load_model(f\"model/{model_variant}/{scats_number}/{model_variant}_{scats_number}.h5\", custom_objects={'mse': 'mse'})\n",
    "                except:\n",
    "                    print(f'No model found for {model_variant} in {scats_number}... assuming not trained, removing from models to test.')\n",
    "                    # don't remove during iteration as it will result in unintended behaviour\n",
    "                    models_to_remove.append(model_variant)\n",
    "                    continue\n",
    "                \n",
    "                X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "                predicted = model.predict(X_test)\n",
    "                predicted = scaler.inverse_transform(predicted.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "                y_preds.append(predicted[:96])\n",
    "    \n",
    "                print(f\"Evaluating {model_variant} for SCATS Number: {scats_number}\")\n",
    "                mape, vs, mae, mse, r2 = eva_regress(y_test, predicted, silent=True)\n",
    "    \n",
    "                model_stats = {\n",
    "                    'scats': scats_number,\n",
    "                    'model': model_variant,\n",
    "                    'mape': mape,\n",
    "                    'vs': vs,\n",
    "                    'mae': mae,\n",
    "                    'mse': mse,\n",
    "                    'r2': r2\n",
    "                }\n",
    "    \n",
    "                stats_row_list.append(model_stats)\n",
    "\n",
    "            \n",
    "            for model_variant in models_to_remove:\n",
    "                models.remove(model_variant)\n",
    "\n",
    "    stats_df = pd.DataFrame(stats_row_list)\n",
    "    stats_df.set_index('scats')\n",
    "\n",
    "    stats_df.to_csv('intersections_test_results.csv')\n",
    "    #plot_results(y_test[:96], y_preds, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d8237a-4b68-443a-8616-478e0c318a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc84eb-3a19-40bc-864d-273d24861cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
